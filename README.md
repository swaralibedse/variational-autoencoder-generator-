# variational-autoencoder-generator-
Variational Autoencoder (VAE) for molecular SMILES generation trained on the MOSES dataset â€” part of the MolVista AI project for AI-powered drug discovery.
# ğŸ§¬ MolVista AI â€“ VAE Molecule Generator

This module implements a **Variational Autoencoder (VAE)** for generating molecular SMILES strings, trained on the **MOSES dataset**.
It is a key component of **MolVista AI â€“ AI-Powered Molecular Docking & Drug Generation for Accelerated Drug Discovery**.

---

## ğŸŒ Overview

**MolVista AI** aims to accelerate early-stage drug discovery by combining:

* ğŸ§  **Deep Generative Models (VAE)** for molecule creation
* ğŸ§© **Graph Neural Networks (GNN)** for binding affinity prediction
* ğŸ§« **AI-assisted Docking and Visualization**

This **VAE Molecule Generator** learns molecular patterns from SMILES strings and generates new, chemically valid molecules.

---

## ğŸ—ï¸ Project Architecture

Below is the conceptual flow of the **VAE Molecule Generator** module within MolVista AI:

```
                   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                   â”‚     MOSES Dataset (SMILES)   â”‚
                   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                  â”‚
                                  â–¼
                       â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                       â”‚   tokenizer.py     â”‚
                       â”‚ (Encode/Decode)    â”‚
                       â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                â”‚
                                â–¼
                        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                        â”‚   vae.py     â”‚
                        â”‚ (Encoder +   â”‚
                        â”‚  Decoder)    â”‚
                        â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
                               â”‚
                               â–¼
                     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                     â”‚   train_vae.py      â”‚
                     â”‚  (Training Loop)    â”‚
                     â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚
                 â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                 â”‚                                            â”‚
                 â–¼                                            â–¼
       â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                       â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
       â”‚ sample_vae.py    â”‚                       â”‚ evaluate.py      â”‚
       â”‚ Generate SMILES  â”‚                       â”‚ Uniqueness Check â”‚
       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Output Files:
 - vae_model.pt
 - loss_curve.png
 - sample_output.txt
 - uniqueness.txt
```

---

## ğŸ”§ Components

| File                  | Description                                       |
| --------------------- | ------------------------------------------------- |
| `tokenizer.py`        | Tokenizes and detokenizes SMILES strings          |
| `vae.py`              | PyTorch-based MoleculeVAE model (Encoderâ€“Decoder) |
| `train_vae.py`        | Trains VAE model with checkpoint resumption       |
| `sample_vae.py`       | Samples and decodes new molecules                 |
| `evaluate.py`         | Computes uniqueness percentage                    |
| `models/vae_model.pt` | Saved trained model weights                       |
| `loss_curve.png`      | Reconstruction + KL Loss visualization            |

---

## ğŸ“ Dataset

This module uses the **MOSES dataset**, a benchmark for generative molecule models.
Your dataset file should be named **`moses_train.csv`** and include a column named `SMILES`.

Example:

```csv
SMILES
CCO
C1=CC=CC=C1
CC(=O)OC1=CC=CC=C1C(=O)O
```

---

## ğŸ“ˆ Outputs

| Output              | Description                              |
| ------------------- | ---------------------------------------- |
| `vae_model.pt`      | Trained model weights (saved per epoch)  |
| `loss_curve.png`    | Plot of Reconstruction + KL Loss         |
| `sample_output.txt` | Input vs Decoded SMILES samples          |
| `uniqueness.txt`    | Percentage of unique generated molecules |

---

## â–¶ï¸ Training & Usage

To train, generate samples, and evaluate results, follow these commands:

```bash
# 1. Activate environment
conda activate molvista

# 2. Navigate to project
cd C:\molvista-ai

# 3. Set Python path
set PYTHONPATH=C:\molvista-ai

# 4. Train or resume VAE
python generator/scripts/train_vae.py
# â†’ Saves model (vae_model.pt) and loss curve (loss_curve.png)

# 5. Sample new molecules
python generator/scripts/sample_vae.py
# â†’ Outputs sample_output.txt (Input vs Decoded SMILES)

# 6. Evaluate uniqueness
python generator/scripts/evaluate.py
# â†’ Outputs uniqueness.txt (Unique SMILES %)
```

---

## ğŸ§  Model Details

* **Framework:** PyTorch
* **Architecture:** Variational Autoencoder (Encoder + Decoder)
* **Input Representation:** SMILES strings
* **Latent Space:** Continuous vector space for molecule encoding
* **Loss Function:**

  * Reconstruction Loss
  * KL Divergence Loss
* **Optimization:** Adam optimizer

The VAE learns to encode molecular structure into a latent space and decode it back into valid SMILES â€” enabling *de novo* molecule generation.

---

## ğŸ§© Example Results

**Loss Curve:**
Displays reconstruction + KL divergence loss over epochs.
*File: `loss_curve.png`*

**Sample Output:**

```
Input SMILES  â†’  Decoded SMILES
CCO           â†’  CCO
C1=CC=CC=C1   â†’  C1=CC=CC=C1
CC(=O)OCC     â†’  CC(=O)OCC
```

**Uniqueness Report:**

```
Unique SMILES: 92.4%
```

---

## ğŸš€ Features

* âœ… Trainable VAE model for molecular SMILES
* âœ… Resume training from checkpoints
* âœ… Automatic generation & uniqueness evaluation
* âœ… Visualization of training progress
* âœ… Modular design (easy integration with future GNN modules)

---

## ğŸ”¬ Future Work

Upcoming modules in **MolVista AI** will include:

* **GNN-Based Binding Affinity Predictor**
  Predicts how strongly generated molecules bind to target proteins.

* **Conditional Molecule Generation**
  Control properties like logP or QED during generation.

* **Integration with Docking Pipelines**
  For end-to-end AI-driven drug design.

---

## ğŸ“œ Citation

If you use this work or codebase, please cite:

> Bedse, Swarali (2025). *MolVista AI â€“ VAE Molecule Generator: A Variational Autoencoder for Molecular SMILES Generation.*

---

## ğŸ‘©â€ğŸ’» Author

**Swarali Bedse**
Final Year B.Tech â€“ Artificial Intelligence & Data Science
ğŸ“« [LinkedIn](https://www.linkedin.com) â€¢ [GitHub](https://github.com/shreeyan)

---

## ğŸ–¼ï¸ Suggested Repository Banner

**Title:** *AI Generating Molecules*
Image Idea: A glowing neural network creating molecular structures â€” symbolizing AI chemistry.
Find one on [Unsplash](https://unsplash.com/s/photos/ai-molecule) or [Pexels](https://www.pexels.com/search/ai%20molecule/).

---

## ğŸ·ï¸ Tags

`#DeepLearning` `#DrugDiscovery` `#GenerativeAI` `#PyTorch` `#MolecularDesign` `#AI` `#ComputationalChemistry` `#MachineLearning` `#VAE` `#Bioinformatics`
